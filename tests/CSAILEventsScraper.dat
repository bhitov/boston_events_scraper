(dp0
S'created_at'
p1
cdatetime
datetime
p2
(S'\x07\xdd\x0b\x13\x17\x08\x0b\x03P\\'
p3
tp4
Rp5
sS'results'
p6
(lp7
(dp8
S'description'
p9
VWe show how Theory of Computation has revolutionized our millenary notion of a proof, revealing its unexpected applications to our new digital world. \u000aIn particular, we shall demonstrate how interaction can make proofs much easier to verify, dramatically limit the amount of knowledge released, and yield the most secure identification schemes to date.\u000a\u000aLargely based on joint work with Shafi Goldwasser.  \u000a\u000aSilvio Micali has received his Laurea in Mathematics from the University of Rome, and his PhD in Computer Science from the University of California at Berkeley. Since 1983 he has been a member of the MIT faculty, in Electrical Engineering and Computer Science Department, and of the Computer Science and Artificial Intelligence Laboratory.\u000a\u000aSilvio\u2019s research interests are cryptography, zero knowledge, pseudo-random generation, secure protocols, and mechanism design. \u000aSilvio has received the Turing Award, the Gödel Prize, and the RSA prize He is a member of the National Academy of Sciences, the National Academy of Engineering, and the American Academy of Arts and Sciences. \u000a\u000a
p10
sS'title'
p11
VDertouzos Distinguished Lecture: Proof, Secrets, and Computation
p12
sS'scrape_url'
p13
S'https://calendar.csail.mit.edu/event_calendar.ics'
p14
sS'datetime_start'
p15
g2
(S'\x07\xdd\x0c\x05\x15\x00\x00\x00\x00\x00'
p16
cpytz
_UTC
p17
(tRp18
tp19
Rp20
sS'location'
p21
V32-123
p22
sS'datetime_end'
p23
g2
(S'\x07\xdd\x0c\x05\x16\x1e\x00\x00\x00\x00'
p24
g18
tp25
Rp26
sa(dp27
g9
VThe Cryptographic Lens\u000a\u000aTBA
p28
sg11
VDertouzos Distinguished Lecture
p29
sg13
g14
sg15
g2
(S'\x07\xde\x05\x01\x14\x00\x00\x00\x00\x00'
p30
g18
tp31
Rp32
sg21
VTBA
p33
sg23
g2
(S'\x07\xde\x05\x01\x15\x1e\x00\x00\x00\x00'
p34
g18
tp35
Rp36
sa(dp37
g9
VAbstract: Theoretical results in cryptography provide various techniques for outsourcing computation with strong integrity and confidentiality guarantees. Yet, these techniques continue to suffer from high overheads in the general case.  In this work, we significantly reduce the aforementioned costs via a combination of new theoretical and engineering techniques. Concretely, we present a new system for proving the correctness of high-level program executions. Proofs in our system are non-interactive, short (less than 300 bytes), and can be verified publicly in milliseconds. Moreover, our proofs are zero-knowledge proofs of knowledge.  Our work raises additional intriguing mathematical questions, whose solutions could push outsourced computation even further.  \u000a\u000a*Joint work with Eli Ben-Sasson, Daniel Genkin, Eran Tromer, and Madars Virza.\u000a
p38
sg11
VSNARKS FOR C: VERIFYING PROGRAM EXECUTIONS SUCCINCTLY AND IN ZERO KNOWLEDGE
p39
sg13
g14
sg15
g2
(S'\x07\xdd\x0b\x16\x0f\x1e\x00\x00\x00\x00'
p40
g18
tp41
Rp42
sg21
V32-G449
p43
sg23
g2
(S'\x07\xdd\x0b\x16\x11\x00\x00\x00\x00\x00'
p44
g18
tp45
Rp46
sa(dp47
g9
VThis talk describes an approach to learning improved acoustic feature vectors for automatic speech recognition.  Typically, speech recognizers use a parametrization of the acoustic signal based on mel-frequency cepstral coefficients (MFCCs), perceptual linear prediction coefficients (PLPs), or related representations.  It is often possible to improve performance by forming large feature vectors consisting of multiple consecutive frames of such standard features, followed by dimensionality reduction using a learned transformation.  The learned transformation may be unsupervised (e.g., principal components analysis) or supervised (e.g., linear discriminant analysis, neural network-based representations).\u000a \u000aThis talk will describe a recent approach that is unsupervised, but using a second "view" of the data (in our case, articulatory measurements) as additional information for transformation learning.  The approach we take, using canonical correlation analysis (CCA) and its nonlinear extensions, finds representations of the two views that are maximally correlated.  This approach avoids some of the disadvantages of other unsupervised methods, such as PCA, which are sensitive to noise and data scaling, and possibly of supervised methods, which are more task-specific.\u000a\u000aThis talk will cover recent work in this setting using CCA, its nonlinear extension via kernel CCA, and a newly proposed, parametric nonlinear extension using deep neural networks dubbed deep CCA.  Results to date show that the approach can be used to improve performance on tasks such as phonetic classification and recognition, and that the improvements generalize to new speakers for which no data from the second view is available.\u000a\u000aTime permitting, the talk will also include additional recent work using articulatory information for other tasks, including low-resource spoken term detection, lexical access, and sign language recognition.\u000a\u000aKaren Livescu is an Assistant Professor at TTI-Chicago.  She completed her PhD at MIT in the CSAIL Spoken Language Systems group, and was a post-doctoral lecturer in the MIT EECS department.  Karen's main research interests are in speech and language processing, with a slant toward combining machine learning with knowledge about linguistics and speech science.  Her recent work has included multi-view learning of speech representations, articulatory models of pronunciation variation, discriminative training with low resources for spoken term detection and pronunciation modeling, and automatic sign language recognition.  She is a member of the IEEE Spoken Language Technical Committee, associate editor for IEEE Transactions on Audio, Speech, and Language Processing, and subject editor for Speech Communication.  She is an organizer/co-organizer of a number of recent workshops, including the ISCA SIGML workshops on Machine Learning in Speech and Language Processing, the Midwest Speech and Language Days, and the Interspeech Workshop on Speech Production in Automatic Speech Recognition.\u000a\u000a
p48
sg11
VMulti-view Learning of Speech Features with Linear and Non-linear Canonical Correlation Analysis
p49
sg13
g14
sg15
g2
(S'\x07\xdd\x0b\x19\x15\x00\x00\x00\x00\x00'
p50
g18
tp51
Rp52
sg21
V32-G882 (Stata Center - Hewlett Room)
p53
sg23
g2
(S'\x07\xdd\x0b\x19\x16\x00\x00\x00\x00\x00'
p54
g18
tp55
Rp56
sa(dp57
g9
VWe present a new data structure for the c-approximate near neighbor problem (ANN) in the Euclidean space. For n points in Rd, our algorithm achieves Oc(dn?) query time and Oc(n1+?+nd) space, where ??7/(8c2)+O(1/c3)+oc(1). This is the first improvement over the result by Andoni and Indyk (FOCS 2006) and the first data structure that bypasses a locality-sensitive hashing lower bound proved by O'Donnell, Wu and Zhou (ICS 2011). By a standard reduction we obtain a data structure for the Hamming space and ?1 norm with ??7/(8c)+O(1/c3/2)+oc(1), which is the first improvement over the result of Indyk and Motwani (STOC 1998). Our data structure is able to bypass the locality-sensitive hashing barrier by using data-dependent hash functions (previous work used functions that are oblivious to the data). Joint work with Alexandr Andoni, Piotr Indyk and Nguy?n Lê Huy A short summary of the paper can be found here.\u000a
p58
sg11
VBeyond Locality-Sensitive Hashing 
p59
sg13
g14
sg15
g2
(S'\x07\xdd\x0b\x14\x15\x00\x00\x00\x00\x00'
p60
g18
tp61
Rp62
sg21
V32 G575
p63
sg23
g2
(S'\x07\xdd\x0b\x14\x16\x00\x00\x00\x00\x00'
p64
g18
tp65
Rp66
sa(dp67
g9
VTBA
p68
sg11
VAnkit Sharma TALK 
p69
sg13
g14
sg15
g2
(S'\x07\xdd\x0b\x19\x15\x00\x00\x00\x00\x00'
p70
g18
tp71
Rp72
sg21
V32-G575
p73
sg23
g2
(S'\x07\xdd\x0b\x19\x16\x00\x00\x00\x00\x00'
p74
g18
tp75
Rp76
sa(dp77
g9
VAbstract:\u000a\u000aEmerging robots have the potential to improve healthcare delivery, from enabling surgical procedures that are beyond current clinical capabilities to autonomously assisting people with daily tasks in their homes. In this talk, we will discuss new algorithms to enable medical and assistive robots to safely and semi-autonomously operate inside people's bodies or homes. These algorithms must compensate for uncertainty due to variability in humans and the environment, consider deformations of soft tissues, guarantee safety, and integrate human expertise into the motion planning process. \u000a\u000aFirst, we will discuss how our new algorithms apply to two recently created medical devices for neurosurgery and cardiothoracic surgery: steerable needles and tentacle-like robots. These new devices can maneuver around anatomical obstacles to perform procedures at clinical sites inaccessible to traditional straight instruments. To ensure patient safety, our algorithms explicitly consider uncertainty in motion and sensing to maximize the probability of avoiding obstacles and successfully accomplishing the task. We compute motion policies by integrating physics-based biomechanical simulations, optimal control, parallel computation, and sampling-based motion planners. Second, we will discuss how our new algorithms apply to autonomous robotic assistance for tasks of daily living in the home. We will present demonstration-guided motion planning, an approach in which the robot first learns time-dependent features of an assistive task from human-conducted demonstrations and then autonomously plans motions to accomplish the learned task in new environments with never-before-seen obstacles. \u000a\u000aBio:\u000aDr. Ron Alterovitz is an Assistant Professor in Computer Science at the University of North Carolina at Chapel Hill. He leads the Computational Robotics Research Group which investigates new algorithms to enable robots to safely and autonomously complete novel tasks in clinical and home environments. Prior to joining UNC-Chapel Hill in 2009, Dr. Alterovitz earned his B.S. with Honors from Caltech, completed his Ph.D. at the University of California, Berkeley, and conducted postdoctoral research at the UCSF Comprehensive Cancer Center and the Robotics and AI group at LAAS-CNRS (National Center for Scientific Research) in Toulouse, France. Dr. Alterovitz has co-authored a book on Motion Planning in Medicine, was co-awarded a patent for a medical device, and has received multiple best paper finalist awards at IEEE robotics conferences. He is the recipient of an NIH Ruth L. Kirschstein National Research Service Award, the UNC Computer Science Department's Excellence in Teaching Award, and an NSF CAREER award. \u000aResearch group web site: http://robotics.cs.unc.edu\u000a
p78
sg11
VComputing Motions for Medical and Assistive Robots
p79
sg13
g14
sg15
g2
(S'\x07\xdd\x0b\x16\x14\x00\x00\x00\x00\x00'
p80
g18
tp81
Rp82
sg21
VKiva, 32-G449
p83
sg23
g2
(S'\x07\xdd\x0b\x16\x15\x00\x00\x00\x00\x00'
p84
g18
tp85
Rp86
sa(dp87
g9
V\u000a\u000aWe present an explicit pseudorandom generator for oblivious, read-once, permutation branching programs of constant width that can read their input bits in any order. The seed length is O(log2n), where n is the length of the branching program. The previous best seed length known for this model was n1/2+o(1), which follows as a special case of a generator due to Impagliazzo, Meka, and Zuckerman (FOCS 2012) (which gives a seed length of s1/2+o(1) for arbitrary branching programs of size s). Our techniques also give seed length n1/2+o(1) for general oblivious, read-once branching programs of width 2no(1), which is incomparable to the results of Impagliazzo et al.\u000a\u000aOur pseudorandom generator is similar to the one used by Gopalan et al. (FOCS 2012) for read-once CNFs, but the analysis is quite different; ours is based on Fourier analysis of branching programs. In particular, we show that an oblivious, read-once, regular branching program of width w has Fourier mass at most (2w2)k at level k, independent of the length of the program.\u000a\u000aJoint work with Omer Reingold and Salil Vadhan. See the ECCC report.\u000a  
p88
sg11
VPseudorandomness for Regular Branching Programs via Fourier Analysis
p89
sg13
g14
sg15
g2
(S'\x07\xdd\x0c\x04\x15\x00\x00\x00\x00\x00'
p90
g18
tp91
Rp92
sg21
V32-G575
p93
sg23
g2
(S'\x07\xdd\x0c\x04\x16\x00\x00\x00\x00\x00'
p94
g18
tp95
Rp96
sa(dp97
g9
Vtba
p98
sg11
VInformation causality, Szemerédi-Trotter and algebraic variants of CHSH 
p99
sg13
g14
sg15
g2
(S'\x07\xdd\x0c\x0b\x15\x00\x00\x00\x00\x00'
p100
g18
tp101
Rp102
sg21
V32-G575
p103
sg23
g2
(S'\x07\xdd\x0c\x0b\x16\x00\x00\x00\x00\x00'
p104
g18
tp105
Rp106
sa(dp107
g9
VKeyword spotting, the task of finding words or phrases of interest in audio, is related to, but still quite different from that of speech recognition, where a verbatim transcript is desired. Keyword spotting has the objective of extracting specific, content-bearing words or phrases, and this makes it crucial to use a performance measure that does not weight all word tokens equally. One such measure is the Actual Term Weighted Value (ATWV), which has been used in the IARPA-funded Babel project, and this talk is focused on techniques that have its maximization as the optimization objective. Two such techniques are score normalization and system combination. Score normalization aims at converting the scores of different keywords so that they are commensurate with each other, and they more closely correspond to the probability of being correct than raw posteriors. System combination merges the detections of multiple systems together, thus combining the strengths of different detection modalities, tokenizations, or models. Both of these techniques were applied successfully by BBN in the official evaluation of the Babel project in March/April of 2013, resulting in large gains, of the order of 8-10 points (absolute) in five different languages.\u000a\u000a(This work was done in collaboration with Richard M. Schwartz; the contribution of BBN colleagues S. Tsakalidis, I. Bulyko, L. Zhang, S. Ranjan, T. Ng, R. Hsiao, G. Saikumar, L. Nguyen, J. Makhoul, as well as other members of the BABELON team, is gratefully acknowledged.)\u000a\u000aDamianos Karakos has been a Research Scientist with Raytheon BBN Technologies since June 2012. He obtained the PhD in Electrical Engineering from the University of Maryland in 2002. He was a postdoctoral fellow in the Department of Electrical Engineering and the Center for Language and Speech Processing at Johns Hopkins University between 2003 and 2007. He became Assistant Research Professor in 2007, and, additionally, Research Scientist with the Human Language Technology Center of Excellence at JHU in 2011. His research interests lie in the general area of statistical pattern recognition, with a focus on speech and language applications.\u000a\u000a\u000a
p108
sg11
VScore Normalization and System Combination for Keyword Spotting in Speech
p109
sg13
g14
sg15
g2
(S'\x07\xdd\x0b\x15\x15\x00\x00\x00\x00\x00'
p110
g18
tp111
Rp112
sg21
V32-G882 (Stata Center - Hewlett Room)
p113
sg23
g2
(S'\x07\xdd\x0b\x15\x16\x00\x00\x00\x00\x00'
p114
g18
tp115
Rp116
sa(dp117
g9
VSpeaker: Prof. Stephen Chong, Harvard University\u000a\u000aAbstract: Reasoning about the security of shell scripts is notoriously hard: it is difficult for programmers to deduce the effects of shell scripts on the underlying operating system. First, resource references, such as file paths, are typically resolved lazily and subject to race conditions. Second, shell scripts are typically run with the same privileges as the invoking user, making it hard to determine or enforce that a script has all (and only) permissions to execute successfully. Third, shell scripts invoke other programs, often arbitrary binaries.\u000a\u000aIn this talk, I present the preliminary design and implementation of Shill, a new secure shell scripting language that uses fine-grained capabilities to restrict access to resources. Capabilities bind resources at the time of their creation, and avoid vulnerabilities arising from lazy name resolution. Shill scripts come with a declarative interface that specifies and restricts which capabilities the script may use. A Shill script can invoke an arbitrary binary in a sandbox that limits the privileges of the binary based on a set of capabilities. Capabilities together with declarative interfaces and sandboxing enable the caller of a script to reason precisely about which resources a script (and the binaries it calls) may access, and thus, Shill helps reason safely and effectively about the use and composition of scripts. We have implemented Shill on top of FreeBSD, using Racket and the FreeBSD Trusted MAC framework.\u000a\u000aBio: Steve Chong is a Computer Science faculty member in the Harvard School of Engineering and Applied Sciences. Steve's research focuses on programming languages, information security, and the intersection of these two areas. He is the recipient of an NSF CAREER award, and an AFOSR Young Investigator award. He received a PhD from Cornell University, and a bachelor's degree from Victoria University of Wellington, New Zealand.\u000a
p118
sg11
VShill: A Secure Shell Scripting Language
p119
sg13
g14
sg15
g2
(S'\x07\xdd\x0b\x14\x15\x00\x00\x00\x00\x00'
p120
g18
tp121
Rp122
sg21
VG882
p123
sg23
g2
(S'\x07\xdd\x0b\x14\x16\x00\x00\x00\x00\x00'
p124
g18
tp125
Rp126
sa(dp127
g9
VAbstract: Over the past three decades, communication complexity has found\u000aapplications in nearly every area of computer science, and constitutes\u000aone of the few known techniques for proving unconditional lower\u000abounds. Developing tools in communication complexity is therefore a\u000apromising approach for making progress in other computational models\u000asuch as circuit complexity, streaming, data structures, and privacy to\u000amention a few.\u000a\u000aOne striking example of such tool is information theory, introduced by\u000aShannon in the late 1940's in the context of the one way data\u000atransmission problem. Shannon's work revealed the intimate connection\u000abetween information and communication, namely, that the amortized\u000atransmission cost of a random message is equal to the amount of\u000ainformation it contains. This compression theory, however, does not\u000areadily convert to interactive setups, where two (or more) parties\u000amust engage in a multi-round conversation to accomplish a task.\u000a\u000aThe goal of our ongoing research is to extend this theory, develop the\u000aright tools, and understand how information behaves in interactive\u000asetups, such as the communication complexity model. In this\u000aintroductory talk, I will give an overview of Information Complexity,\u000aan interactive analogue of Shannon's theory. I will describe some of\u000athe main open problems in this emerging field, and some of the\u000ainteresting applications we found, including an exact bound on the\u000acommunication complexity of the Set Disjointness function (~0.48n),\u000aand how information helps us understand the limits of parallel\u000acomputation.
p128
sg11
V Information Complexity and Applications 
p129
sg13
g14
sg15
g2
(S'\x07\xdd\x0b\x1a\x15\x0f\x00\x00\x00\x00'
p130
g18
tp131
Rp132
sg21
V32-G449
p133
sg23
g2
(S'\x07\xdd\x0b\x1a\x16\x0f\x00\x00\x00\x00'
p134
g18
tp135
Rp136
sa(dp137
g9
VAbstract:\u000a\u000aNon-malleable codes, introduced by Dziembowski, Pietrzak and Wichs (ICS 2010) and motivated by applications in tamper-resilient cryptography, encode messages in a manner so that tampering the codeword causes the decoder to either output the correct message or an uncorrelated message. While this relaxation of error detection is an impossible goal to achieve against unrestricted tampering functions, rather surprisingly non-malleable coding becomes possible against any fixed family of tampering functions that is not too large.\u000a\u000aIn this talk, I will discuss the following:\u000a\u000a1. "Capacity" of non-malleable codes: For any tampering family of a prescribed size, we derive an explicit lower bound on the maximum possible rate of a non-malleable code against the given family. Furthermore, we show that this bound is essentially optimal.\u000a\u000a2. An efficient Monte-Carlo construction of non-malleable codes against any family of tampering functions of exponential size (e.g., polynomial-sized Boolean circuits). Codes obtained by this construction achieve rates arbitrarily close to 1 and do not rely on any unproven assumptions.\u000a\u000a3. The specific family of bit-tampering adversaries, that is adversaries that independently act on each encoded bit. For this family, we are able to obtain an explicit construction of non-malleable codes achieving rate arbitrarily close to 1.\u000a\u000aBased on joint work with Venkatesan Guruswami and articles arXiv:1309.0458 (ITCS 2014) and arXiv:1309.1151 (TCC 2014).\u000a
p138
sg11
VCapacity and Constructions of Non-Malleable Codes
p139
sg13
g14
sg15
g2
(S'\x07\xdd\x0c\x03\x15\x0f\x00\x00\x00\x00'
p140
g18
tp141
Rp142
sg21
V32-G449
p143
sg23
g2
(S'\x07\xdd\x0c\x03\x16\x0f\x00\x00\x00\x00'
p144
g18
tp145
Rp146
sa(dp147
g9
VIt's easy to see the increasing costs of a sedentary culture, from pain and stress taking us out of work, to other lifestyle conditions costing health care services to treat. A challenge in HCI is to consider where and how interactive technology may be developed to help address these issues, based on the sense that time with an app is cheaper and more readily accessible than time with a human expert.  That said, much work around health and wellbeing in HCI has focused on a single area: persuasive technologies to encourage people to maintain "healthy" practices, from moving more to eating less.  By looking at where and how people explore health practices, in the context of our daily lives, we see that such focus may represent only a small part of the design space for consideration, and perhaps not represent where the greatest challenge/benefit tradeoff for effect may be. In this talk i'll go over a four part framework for a principled way to look at the design space for wellbeing, including (1) being in-bodied (as opposed to embodied) (2) decision cycles (3) routine practices and (4) technology as culture as technology. Looking forward to your thoughts and feedback.\u000a\u000abio: m.c. schraefel, ph.d, f.bcs, c.eng, cscs, holds the post Professor of Computer Science and Human Performance in the Agents, Interaction and Complexity Group of Electronics and Computer Science, University of Southampton, UK (http://www.ecs.soton.ac.uk/~mc). mc also holds a Research Chair sponsored by the Royal Academy of Engineering and Microsoft Research UK to investigate how to design interactive technology to better support creativity, innovation and discovery. As part of that research, schraefel utilises her work with athletes and researchers as a professional strength and conditioning, movement and nutrition coach for unique insights into people's longitudinal experience of and challenges with wellbeing practice. \u000amc can be found on twitter / facebook @mcphoo\u000aher wellbeing coaching likewise @begin2dig and begin2dig.com
p148
sg11
VCharting the space of wellbeing design for HCI Research and Evaluation in Four movements
p149
sg13
g14
sg15
g2
(S'\x07\xdd\x0b\x16\x12\x00\x00\x00\x00\x00'
p150
g18
tp151
Rp152
sg21
V32-G449 (Kiva)
p153
sg23
g2
(S'\x07\xdd\x0b\x16\x13\x00\x00\x00\x00\x00'
p154
g18
tp155
Rp156
sa(dp157
g9
VIn a seminal 2001 article in the Scientific American, Tim Berners-Lee, Jim Hendler, and Ora Lassila laid out their vision of the Semantic Web. In this vision, software agents use machine understandable "semantic" data to do everything for us from scheduling appointments to booking tickets and even identifying appropriate healthcare providers. However, this vision did not turn into a reality and the Semantic Web failed to take off. In 2006, Tim Berners-Lee and others proposed a set of simple design principles, Linked Data, that used a subset of Semantic Web standards to enable structured data to be easily found, exchanged, and manipulated. This more foundational element of the Semantic Web moved away from large complex ontologies to simpler semantics with a view of pushing machine understandable data to the forefront. The last few years have seen an astronomic rise in the amount of Linked Data online. However, Linked Data has yet to reach the pace at which the Web is growing. Why isn\u2019t there more Linked Data? What are the factors preventing greater deployment and use of Linked Data? Is it all a matter of engineering or are there any research challenges? Is Linked Data a good idea, or simply a rebranding of the Semantic Web? What is the vision for Linked Data? Come and hear experts in the field debate these and other questions related to the challenges of Linked Data.\u000a\u000aPanelists:\u000aTim Berners-Lee: http://www.w3.org/People/Berners-Lee/\u000aHelena F. Deus: http://lenadeus.info\u000aJim Hendler http://www.cs.rpi.edu/~hendler/\u000aDavid Karger: http://people.csail.mit.edu/karger/\u000aMona Vernon: http://gracehopper.org/2013/speaker/mona-vernon/\u000aDavid Wood: http://3roundstones.com/about-us/leadership-team/david-wood/
p158
sg11
VPanel on Challenges of Linked Data
p159
sg13
g14
sg15
g2
(S'\x07\xdd\x0b\x1a\x12\x00\x00\x00\x00\x00'
p160
g18
tp161
Rp162
sg21
V32-155
p163
sg23
g2
(S'\x07\xdd\x0b\x1a\x13\x1e\x00\x00\x00\x00'
p164
g18
tp165
Rp166
sa(dp167
g9
VRecent technology scaling has led to the realization that communication, and not computation, dominates energy costs. This realization, coupled with the constant increase of parallelism and the fact that power consumption is typically the primary design constraint, results in increased difficulty in providing sufficient communication bandwidth to keep processors busy. Power is a critical challenge for HPC, datacenters and consumer electronics. In HPC, a 1000x improvement is performance is needed with only a 10x increase in power by 2018. Moreover, datacenters require $7B just for cooling in the USA, which is projected to increase by four times in the near future. Finally, consumer electronics require a 2x increase in performance with no increase in power every two years to remain competitive.\u000aIn this talk, I will present a my work that addresses efficient data movement on and off chips, and DRAM access. I will focus on collective memory transfers, which maximize DRAM performance and minimize power in stencil computations by guaranteeing in-order access patterns. I will also focus on the channel reservation protocol, which eliminates congestion in system-wide networks in order to increase throughput and reduce latency for benign traffic, and therefore increase the utilization of costly network bandwidth.\u000a\u000aBio:\u000a\u000aGeorge Michelogiannakis is currently a postdoctoral research fellow at the Lawrence Berkeley National Laboratory. He is part of the computer architecture laboratory which examines key computer architecture research challenges both on and off chip. He completed his PhD at Stanford University in 2012 with Prof. William J. Dally. His past work focuses on on-chip network with numerous contributions to flow control, congestion, allocation, and co-design with chip multiprocessors. His other work includes congestion control for system-wide networks, precision loss avoidance for system-wide reduction operations, and maximizing DRAM efficiency by taking advantage of advanced language constructs. George Michelogiannakis was the recipient of the Stanford Graduate Fellowship, and numerous other awards during his previous studies. 
p168
sg11
VThe constant battle for power-efficient computing 
p169
sg13
g14
sg15
g2
(S'\x07\xdd\x0c\x04\x13\x1e\x00\x00\x00\x00'
p170
g18
tp171
Rp172
sg21
V32-G882
p173
sg23
g2
(S'\x07\xdd\x0c\x04\x15\x00\x00\x00\x00\x00'
p174
g18
tp175
Rp176
sa(dp177
g9
VAbstract: In this talk I will describe nondeterministic reductions which yield new direct product theorems (DPTs) for Boolean circuits. In our theorems one assumes that a function F is "mildly hard" against *nondeterministic* circuits of some size s(n), and concludes that the t-fold direct product F^t is "extremely hard" against probabilistic circuits of only polynomially smaller size s'(n). The main advantage of these results compared with previous DPTs is the strength of the size bound in our conclusion. As an application, we show that if NP is not in coNP/poly then, for every PPT algorithm attempting to produce satisfying assignments to Boolean formulas, there are infinitely many satisfiable instances on which the algorithm's success probability is nearly-exponentially small. This furthers a project of Paturi and Pudlák [STOC'10].
p178
sg11
VNondeterministic Direct Product Reductions and the Success Probability of SAT Solvers
p179
sg13
g14
sg15
g2
(S'\x07\xdd\x0c\n\x15\x0f\x00\x00\x00\x00'
p180
g18
tp181
Rp182
sg21
V32-G449
p183
sg23
g2
(S'\x07\xdd\x0c\n\x16\x0f\x00\x00\x00\x00'
p184
g18
tp185
Rp186
sa(dp187
g9
VAbstract:\u000aThe wide adoption of smartphones has made cellular networks an essential part\u000aof our digital life. However, existing cellular networks suffer from two key\u000aproblems: the lack of access bandwidth and the lack of direct control.\u000a\u000aIn this talk, I will present techniques to address these two key problems\u000athrough the principle of design-in-the-large. Design-in-the-large leverages the\u000anumerous and their emergent behaviors to achieve scalability and flexibility.\u000a\u000aIn particular, to scale access bandwidth at radio access networks, I\u000awill present the design and prototype of Argos, a base station\u000aarchitecture that employs an unprecedented number of antennas\u000asimultaneously to serve a smaller number of mobile devices in the same\u000aband of frequencies. Both analysis and early experimental results\u000asuggest this design can lead to orders of magnitude increase in both\u000aspectral and energy efficiency.\u000a\u000aTo enable direct control of both radio access networks and cellular core\u000anetworks, I will present the design and prototype of SoftRAN and SoftCell\u000arespectively. SoftRAN is a software defined centralized control plane for radio\u000aaccess networks that abstracts all base base stations in a region as a vritual\u000abig-base stations. SoftCell is a software-defined cellular core network\u000aarchitecture that achieves scalability by moving functionality from packet\u000agateways to the many base stations and by aggregating traffic along multiple\u000adimensions\u2014the service policy, the base station, and the mobile device\u2014at\u000adifferent switches in the network.\u000a\u000aThis is joint work with collaborators at Princeton, Rice, Stanford, Yale and\u000aBell Labs.\u000a\u000aBio:\u000aLi Erran Li received his Ph.D. in Computer Science from Cornell\u000aUniversity. Since graduation, he has been with Bell Labs. He is also an\u000aadjunct professor at the Department of Computer Science at Columbia\u000aUniversity, New York. He is an IEEE Fellow. His research interests are in\u000anetworking and systems with a focus on cellular networks and mobile\u000acomputing. He has published over 70 papers and holds 13 US Patents. 
p188
sg11
VMaking Cellular Networks Scalable and Flexible 
p189
sg13
g14
sg15
g2
(S'\x07\xdd\x0b\x15\x14\x00\x00\x00\x00\x00'
p190
g18
tp191
Rp192
sg21
V32-124
p193
sg23
g2
(S'\x07\xdd\x0b\x15\x15\x00\x00\x00\x00\x00'
p194
g18
tp195
Rp196
sasS'url_data'
p197
(dp198
g14
S'BEGIN:VCALENDAR\r\nVERSION:2.0\r\nCALSCALE:GREGORIAN\r\nMETHOD:PUBLISH\r\nPRODID:iCalendar-Ruby\r\nBEGIN:VEVENT\r\nCREATED:20130906T081512\r\nDESCRIPTION:We show how Theory of Computation has revolutionized our millen\r\n ary notion of a proof\\, revealing its unexpected applications to our new di\r\n gital world. \\nIn particular\\, we shall demonstrate how interaction can mak\r\n e proofs much easier to verify\\, dramatically limit the amount of knowledge\r\n  released\\, and yield the most secure identification schemes to date.\\n\\nLa\r\n rgely based on joint work with Shafi Goldwasser.  \\n\\nSilvio Micali has rec\r\n eived his Laurea in Mathematics from the University of Rome\\, and his PhD i\r\n n Computer Science from the University of California at Berkeley. Since 198\r\n 3 he has been a member of the MIT faculty\\, in Electrical Engineering and C\r\n omputer Science Department\\, and of the Computer Science and Artificial Int\r\n elligence Laboratory.\\n\\nSilvio\xe2\x80\x99s research interests are cryptography\\, zer\r\n o knowledge\\, pseudo-random generation\\, secure protocols\\, and mechanism d\r\n esign. \\nSilvio has received the Turing Award\\, the G\xc3\xb6del Prize\\, and the R\r\n SA prize He is a member of the National Academy of Sciences\\, the National \r\n Academy of Engineering\\, and the American Academy of Arts and Sciences. \\n\\\r\n n\r\nDTEND:20131205T223000Z\r\nDTSTAMP:20131119T230810\r\nDTSTART:20131205T210000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131112T093545\r\nLOCATION:32-123\r\nSEQUENCE:0\r\nSUMMARY:Dertouzos Distinguished Lecture: Proof\\, Secrets\\, and Computation\r\nUID:2013-11-19T23:08:10-05:00_987878395@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20130906T081637\r\nDESCRIPTION:The Cryptographic Lens\\n\\nTBA\r\nDTEND:20140501T213000Z\r\nDTSTAMP:20131119T230810\r\nDTSTART:20140501T200000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131010T164627\r\nLOCATION:TBA\r\nSEQUENCE:0\r\nSUMMARY:Dertouzos Distinguished Lecture\r\nUID:2013-11-19T23:08:10-05:00_971279332@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131011T113857\r\nDESCRIPTION:Abstract: Theoretical results in cryptography provide various t\r\n echniques for outsourcing computation with strong integrity and confidentia\r\n lity guarantees. Yet\\, these techniques continue to suffer from high overhe\r\n ads in the general case.  In this work\\, we significantly reduce the aforem\r\n entioned costs via a combination of new theoretical and engineering techniq\r\n ues. Concretely\\, we present a new system for proving the correctness of hi\r\n gh-level program executions. Proofs in our system are non-interactive\\, sho\r\n rt (less than 300 bytes)\\, and can be verified publicly in milliseconds. Mo\r\n reover\\, our proofs are zero-knowledge proofs of knowledge.  Our work raise\r\n s additional intriguing mathematical questions\\, whose solutions could push\r\n  outsourced computation even further.  \\n\\n*Joint work with Eli Ben-Sasson\\\r\n , Daniel Genkin\\, Eran Tromer\\, and Madars Virza.\\n\r\nDTEND:20131122T170000Z\r\nDTSTAMP:20131119T230810\r\nDTSTART:20131122T153000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131104T103334\r\nLOCATION:32-G449\r\nSEQUENCE:0\r\nSUMMARY:SNARKS FOR C: VERIFYING PROGRAM EXECUTIONS SUCCINCTLY AND IN ZERO K\r\n NOWLEDGE\r\nUID:2013-11-19T23:08:10-05:00_332805152@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131024T165311\r\nDESCRIPTION:This talk describes an approach to learning improved acoustic f\r\n eature vectors for automatic speech recognition.  Typically\\, speech recogn\r\n izers use a parametrization of the acoustic signal based on mel-frequency c\r\n epstral coefficients (MFCCs)\\, perceptual linear prediction coefficients (P\r\n LPs)\\, or related representations.  It is often possible to improve perform\r\n ance by forming large feature vectors consisting of multiple consecutive fr\r\n ames of such standard features\\, followed by dimensionality reduction using\r\n  a learned transformation.  The learned transformation may be unsupervised \r\n (e.g.\\, principal components analysis) or supervised (e.g.\\, linear discrim\r\n inant analysis\\, neural network-based representations).\\n \\nThis talk will \r\n describe a recent approach that is unsupervised\\, but using a second "view"\r\n  of the data (in our case\\, articulatory measurements) as additional inform\r\n ation for transformation learning.  The approach we take\\, using canonical \r\n correlation analysis (CCA) and its nonlinear extensions\\, finds representat\r\n ions of the two views that are maximally correlated.  This approach avoids \r\n some of the disadvantages of other unsupervised methods\\, such as PCA\\, whi\r\n ch are sensitive to noise and data scaling\\, and possibly of supervised met\r\n hods\\, which are more task-specific.\\n\\nThis talk will cover recent work in\r\n  this setting using CCA\\, its nonlinear extension via kernel CCA\\, and a ne\r\n wly proposed\\, parametric nonlinear extension using deep neural networks du\r\n bbed deep CCA.  Results to date show that the approach can be used to impro\r\n ve performance on tasks such as phonetic classification and recognition\\, a\r\n nd that the improvements generalize to new speakers for which no data from \r\n the second view is available.\\n\\nTime permitting\\, the talk will also inclu\r\n de additional recent work using articulatory information for other tasks\\, \r\n including low-resource spoken term detection\\, lexical access\\, and sign la\r\n nguage recognition.\\n\\nKaren Livescu is an Assistant Professor at TTI-Chica\r\n go.  She completed her PhD at MIT in the CSAIL Spoken Language Systems grou\r\n p\\, and was a post-doctoral lecturer in the MIT EECS department.  Karen\'s m\r\n ain research interests are in speech and language processing\\, with a slant\r\n  toward combining machine learning with knowledge about linguistics and spe\r\n ech science.  Her recent work has included multi-view learning of speech re\r\n presentations\\, articulatory models of pronunciation variation\\, discrimina\r\n tive training with low resources for spoken term detection and pronunciatio\r\n n modeling\\, and automatic sign language recognition.  She is a member of t\r\n he IEEE Spoken Language Technical Committee\\, associate editor for IEEE Tra\r\n nsactions on Audio\\, Speech\\, and Language Processing\\, and subject editor \r\n for Speech Communication.  She is an organizer/co-organizer of a number of \r\n recent workshops\\, including the ISCA SIGML workshops on Machine Learning i\r\n n Speech and Language Processing\\, the Midwest Speech and Language Days\\, a\r\n nd the Interspeech Workshop on Speech Production in Automatic Speech Recogn\r\n ition.\\n\\n\r\nDTEND:20131125T220000Z\r\nDTSTAMP:20131119T230810\r\nDTSTART:20131125T210000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131024T165311\r\nLOCATION:32-G882 (Stata Center - Hewlett Room)\r\nSEQUENCE:0\r\nSUMMARY:Multi-view Learning of Speech Features with Linear and Non-linear C\r\n anonical Correlation Analysis\r\nUID:2013-11-19T23:08:10-05:00_67541077@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131031T095924\r\nDESCRIPTION:We present a new data structure for the c-approximate near neig\r\n hbor problem (ANN) in the Euclidean space. For n points in Rd\\, our algorit\r\n hm achieves Oc(dn?) query time and Oc(n1+?+nd) space\\, where ??7/(8c2)+O(1/\r\n c3)+oc(1). This is the first improvement over the result by Andoni and Indy\r\n k (FOCS 2006) and the first data structure that bypasses a locality-sensiti\r\n ve hashing lower bound proved by O\'Donnell\\, Wu and Zhou (ICS 2011). By a s\r\n tandard reduction we obtain a data structure for the Hamming space and ?1 n\r\n orm with ??7/(8c)+O(1/c3/2)+oc(1)\\, which is the first improvement over the\r\n  result of Indyk and Motwani (STOC 1998). Our data structure is able to byp\r\n ass the locality-sensitive hashing barrier by using data-dependent hash fun\r\n ctions (previous work used functions that are oblivious to the data). Joint\r\n  work with Alexandr Andoni\\, Piotr Indyk and Nguy?n L\xc3\xaa Huy A short summary \r\n of the paper can be found here.\\n\r\nDTEND:20131120T220000Z\r\nDTSTAMP:20131119T230810\r\nDTSTART:20131120T210000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131031T095924\r\nLOCATION:32 G575\r\nSEQUENCE:0\r\nSUMMARY:Beyond Locality-Sensitive Hashing \r\nUID:2013-11-19T23:08:10-05:00_25277313@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131031T100543\r\nDESCRIPTION:TBA\r\nDTEND:20131125T220000Z\r\nDTSTAMP:20131119T230810\r\nDTSTART:20131125T210000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131031T100543\r\nLOCATION:32-G575\r\nSEQUENCE:0\r\nSUMMARY:Ankit Sharma TALK \r\nUID:2013-11-19T23:08:10-05:00_546163098@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131031T101859\r\nDESCRIPTION:Abstract:\\n\\nEmerging robots have the potential to improve heal\r\n thcare delivery\\, from enabling surgical procedures that are beyond current\r\n  clinical capabilities to autonomously assisting people with daily tasks in\r\n  their homes. In this talk\\, we will discuss new algorithms to enable medic\r\n al and assistive robots to safely and semi-autonomously operate inside peop\r\n le\'s bodies or homes. These algorithms must compensate for uncertainty due \r\n to variability in humans and the environment\\, consider deformations of sof\r\n t tissues\\, guarantee safety\\, and integrate human expertise into the motio\r\n n planning process. \\n\\nFirst\\, we will discuss how our new algorithms appl\r\n y to two recently created medical devices for neurosurgery and cardiothorac\r\n ic surgery: steerable needles and tentacle-like robots. These new devices c\r\n an maneuver around anatomical obstacles to perform procedures at clinical s\r\n ites inaccessible to traditional straight instruments. To ensure patient sa\r\n fety\\, our algorithms explicitly consider uncertainty in motion and sensing\r\n  to maximize the probability of avoiding obstacles and successfully accompl\r\n ishing the task. We compute motion policies by integrating physics-based bi\r\n omechanical simulations\\, optimal control\\, parallel computation\\, and samp\r\n ling-based motion planners. Second\\, we will discuss how our new algorithms\r\n  apply to autonomous robotic assistance for tasks of daily living in the ho\r\n me. We will present demonstration-guided motion planning\\, an approach in w\r\n hich the robot first learns time-dependent features of an assistive task fr\r\n om human-conducted demonstrations and then autonomously plans motions to ac\r\n complish the learned task in new environments with never-before-seen obstac\r\n les. \\n\\nBio:\\nDr. Ron Alterovitz is an Assistant Professor in Computer Sci\r\n ence at the University of North Carolina at Chapel Hill. He leads the Compu\r\n tational Robotics Research Group which investigates new algorithms to enabl\r\n e robots to safely and autonomously complete novel tasks in clinical and ho\r\n me environments. Prior to joining UNC-Chapel Hill in 2009\\, Dr. Alterovitz \r\n earned his B.S. with Honors from Caltech\\, completed his Ph.D. at the Unive\r\n rsity of California\\, Berkeley\\, and conducted postdoctoral research at the\r\n  UCSF Comprehensive Cancer Center and the Robotics and AI group at LAAS-CNR\r\n S (National Center for Scientific Research) in Toulouse\\, France. Dr. Alter\r\n ovitz has co-authored a book on Motion Planning in Medicine\\, was co-awarde\r\n d a patent for a medical device\\, and has received multiple best paper fina\r\n list awards at IEEE robotics conferences. He is the recipient of an NIH Rut\r\n h L. Kirschstein National Research Service Award\\, the UNC Computer Science\r\n  Department\'s Excellence in Teaching Award\\, and an NSF CAREER award. \\nRes\r\n earch group web site: http://robotics.cs.unc.edu\\n\r\nDTEND:20131122T210000Z\r\nDTSTAMP:20131119T230810\r\nDTSTART:20131122T200000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131031T101859\r\nLOCATION:Kiva\\, 32-G449\r\nSEQUENCE:0\r\nSUMMARY:Computing Motions for Medical and Assistive Robots\r\nUID:2013-11-19T23:08:10-05:00_479128375@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131031T142507\r\nDESCRIPTION:\\n\\nWe present an explicit pseudorandom generator for oblivious\r\n \\, read-once\\, permutation branching programs of constant width that can re\r\n ad their input bits in any order. The seed length is O(log2n)\\, where n is \r\n the length of the branching program. The previous best seed length known fo\r\n r this model was n1/2+o(1)\\, which follows as a special case of a generator\r\n  due to Impagliazzo\\, Meka\\, and Zuckerman (FOCS 2012) (which gives a seed \r\n length of s1/2+o(1) for arbitrary branching programs of size s). Our techni\r\n ques also give seed length n1/2+o(1) for general oblivious\\, read-once bran\r\n ching programs of width 2no(1)\\, which is incomparable to the results of Im\r\n pagliazzo et al.\\n\\nOur pseudorandom generator is similar to the one used b\r\n y Gopalan et al. (FOCS 2012) for read-once CNFs\\, but the analysis is quite\r\n  different\\; ours is based on Fourier analysis of branching programs. In pa\r\n rticular\\, we show that an oblivious\\, read-once\\, regular branching progra\r\n m of width w has Fourier mass at most (2w2)k at level k\\, independent of th\r\n e length of the program.\\n\\nJoint work with Omer Reingold and Salil Vadhan.\r\n  See the ECCC report.\\n  \r\nDTEND:20131204T220000Z\r\nDTSTAMP:20131119T230810\r\nDTSTART:20131204T210000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131031T142507\r\nLOCATION:32-G575\r\nSEQUENCE:0\r\nSUMMARY:Pseudorandomness for Regular Branching Programs via Fourier Analysi\r\n s\r\nUID:2013-11-19T23:08:10-05:00_337097948@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131107T164419\r\nDESCRIPTION:tba\r\nDTEND:20131211T220000Z\r\nDTSTAMP:20131119T230810\r\nDTSTART:20131211T210000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131107T164523\r\nLOCATION:32-G575\r\nSEQUENCE:0\r\nSUMMARY:Information causality\\, Szemer\xc3\xa9di-Trotter and algebraic variants of\r\n  CHSH \r\nUID:2013-11-19T23:08:10-05:00_664308448@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131115T163632\r\nDESCRIPTION:Keyword spotting\\, the task of finding words or phrases of inte\r\n rest in audio\\, is related to\\, but still quite different from that of spee\r\n ch recognition\\, where a verbatim transcript is desired. Keyword spotting h\r\n as the objective of extracting specific\\, content-bearing words or phrases\\\r\n , and this makes it crucial to use a performance measure that does not weig\r\n ht all word tokens equally. One such measure is the Actual Term Weighted Va\r\n lue (ATWV)\\, which has been used in the IARPA-funded Babel project\\, and th\r\n is talk is focused on techniques that have its maximization as the optimiza\r\n tion objective. Two such techniques are score normalization and system comb\r\n ination. Score normalization aims at converting the scores of different key\r\n words so that they are commensurate with each other\\, and they more closely\r\n  correspond to the probability of being correct than raw posteriors. System\r\n  combination merges the detections of multiple systems together\\, thus comb\r\n ining the strengths of different detection modalities\\, tokenizations\\, or \r\n models. Both of these techniques were applied successfully by BBN in the of\r\n ficial evaluation of the Babel project in March/April of 2013\\, resulting i\r\n n large gains\\, of the order of 8-10 points (absolute) in five different la\r\n nguages.\\n\\n(This work was done in collaboration with Richard M. Schwartz\\;\r\n  the contribution of BBN colleagues S. Tsakalidis\\, I. Bulyko\\, L. Zhang\\, \r\n S. Ranjan\\, T. Ng\\, R. Hsiao\\, G. Saikumar\\, L. Nguyen\\, J. Makhoul\\, as we\r\n ll as other members of the BABELON team\\, is gratefully acknowledged.)\\n\\nD\r\n amianos Karakos has been a Research Scientist with Raytheon BBN Technologie\r\n s since June 2012. He obtained the PhD in Electrical Engineering from the U\r\n niversity of Maryland in 2002. He was a postdoctoral fellow in the Departme\r\n nt of Electrical Engineering and the Center for Language and Speech Process\r\n ing at Johns Hopkins University between 2003 and 2007. He became Assistant \r\n Research Professor in 2007\\, and\\, additionally\\, Research Scientist with t\r\n he Human Language Technology Center of Excellence at JHU in 2011. His resea\r\n rch interests lie in the general area of statistical pattern recognition\\, \r\n with a focus on speech and language applications.\\n\\n\\n\r\nDTEND:20131121T220000Z\r\nDTSTAMP:20131119T230810\r\nDTSTART:20131121T210000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131115T163632\r\nLOCATION:32-G882 (Stata Center - Hewlett Room)\r\nSEQUENCE:0\r\nSUMMARY:Score Normalization and System Combination for Keyword Spotting in \r\n Speech\r\nUID:2013-11-19T23:08:10-05:00_469772596@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131118T152926\r\nDESCRIPTION:Speaker: Prof. Stephen Chong\\, Harvard University\\n\\nAbstract: \r\n Reasoning about the security of shell scripts is notoriously hard: it is di\r\n fficult for programmers to deduce the effects of shell scripts on the under\r\n lying operating system. First\\, resource references\\, such as file paths\\, \r\n are typically resolved lazily and subject to race conditions. Second\\, shel\r\n l scripts are typically run with the same privileges as the invoking user\\,\r\n  making it hard to determine or enforce that a script has all (and only) pe\r\n rmissions to execute successfully. Third\\, shell scripts invoke other progr\r\n ams\\, often arbitrary binaries.\\n\\nIn this talk\\, I present the preliminary\r\n  design and implementation of Shill\\, a new secure shell scripting language\r\n  that uses fine-grained capabilities to restrict access to resources. Capab\r\n ilities bind resources at the time of their creation\\, and avoid vulnerabil\r\n ities arising from lazy name resolution. Shill scripts come with a declarat\r\n ive interface that specifies and restricts which capabilities the script ma\r\n y use. A Shill script can invoke an arbitrary binary in a sandbox that limi\r\n ts the privileges of the binary based on a set of capabilities. Capabilitie\r\n s together with declarative interfaces and sandboxing enable the caller of \r\n a script to reason precisely about which resources a script (and the binari\r\n es it calls) may access\\, and thus\\, Shill helps reason safely and effectiv\r\n ely about the use and composition of scripts. We have implemented Shill on \r\n top of FreeBSD\\, using Racket and the FreeBSD Trusted MAC framework.\\n\\nBio\r\n : Steve Chong is a Computer Science faculty member in the Harvard School of\r\n  Engineering and Applied Sciences. Steve\'s research focuses on programming \r\n languages\\, information security\\, and the intersection of these two areas.\r\n  He is the recipient of an NSF CAREER award\\, and an AFOSR Young Investigat\r\n or award. He received a PhD from Cornell University\\, and a bachelor\'s degr\r\n ee from Victoria University of Wellington\\, New Zealand.\\n\r\nDTEND:20131120T220000Z\r\nDTSTAMP:20131119T230810\r\nDTSTART:20131120T210000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131118T152926\r\nLOCATION:G882\r\nSEQUENCE:0\r\nSUMMARY:Shill: A Secure Shell Scripting Language\r\nUID:2013-11-19T23:08:10-05:00_383050543@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131118T153206\r\nDESCRIPTION:Abstract: Over the past three decades\\, communication complexit\r\n y has found\\napplications in nearly every area of computer science\\, and co\r\n nstitutes\\none of the few known techniques for proving unconditional lower\\\r\n nbounds. Developing tools in communication complexity is therefore a\\npromi\r\n sing approach for making progress in other computational models\\nsuch as ci\r\n rcuit complexity\\, streaming\\, data structures\\, and privacy to\\nmention a \r\n few.\\n\\nOne striking example of such tool is information theory\\, introduce\r\n d by\\nShannon in the late 1940\'s in the context of the one way data\\ntransm\r\n ission problem. Shannon\'s work revealed the intimate connection\\nbetween in\r\n formation and communication\\, namely\\, that the amortized\\ntransmission cos\r\n t of a random message is equal to the amount of\\ninformation it contains. T\r\n his compression theory\\, however\\, does not\\nreadily convert to interactive\r\n  setups\\, where two (or more) parties\\nmust engage in a multi-round convers\r\n ation to accomplish a task.\\n\\nThe goal of our ongoing research is to exten\r\n d this theory\\, develop the\\nright tools\\, and understand how information b\r\n ehaves in interactive\\nsetups\\, such as the communication complexity model.\r\n  In this\\nintroductory talk\\, I will give an overview of Information Comple\r\n xity\\,\\nan interactive analogue of Shannon\'s theory. I will describe some o\r\n f\\nthe main open problems in this emerging field\\, and some of the\\ninteres\r\n ting applications we found\\, including an exact bound on the\\ncommunication\r\n  complexity of the Set Disjointness function (~0.48n)\\,\\nand how informatio\r\n n helps us understand the limits of parallel\\ncomputation.\r\nDTEND:20131126T221500Z\r\nDTSTAMP:20131119T230810\r\nDTSTART:20131126T211500Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131118T153206\r\nLOCATION:32-G449\r\nSEQUENCE:0\r\nSUMMARY: Information Complexity and Applications \r\nUID:2013-11-19T23:08:10-05:00_992133855@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131118T153644\r\nDESCRIPTION:Abstract:\\n\\nNon-malleable codes\\, introduced by Dziembowski\\, \r\n Pietrzak and Wichs (ICS 2010) and motivated by applications in tamper-resil\r\n ient cryptography\\, encode messages in a manner so that tampering the codew\r\n ord causes the decoder to either output the correct message or an uncorrela\r\n ted message. While this relaxation of error detection is an impossible goal\r\n  to achieve against unrestricted tampering functions\\, rather surprisingly \r\n non-malleable coding becomes possible against any fixed family of tampering\r\n  functions that is not too large.\\n\\nIn this talk\\, I will discuss the foll\r\n owing:\\n\\n1. "Capacity" of non-malleable codes: For any tampering family of\r\n  a prescribed size\\, we derive an explicit lower bound on the maximum possi\r\n ble rate of a non-malleable code against the given family. Furthermore\\, we\r\n  show that this bound is essentially optimal.\\n\\n2. An efficient Monte-Carl\r\n o construction of non-malleable codes against any family of tampering funct\r\n ions of exponential size (e.g.\\, polynomial-sized Boolean circuits). Codes \r\n obtained by this construction achieve rates arbitrarily close to 1 and do n\r\n ot rely on any unproven assumptions.\\n\\n3. The specific family of bit-tampe\r\n ring adversaries\\, that is adversaries that independently act on each encod\r\n ed bit. For this family\\, we are able to obtain an explicit construction of\r\n  non-malleable codes achieving rate arbitrarily close to 1.\\n\\nBased on joi\r\n nt work with Venkatesan Guruswami and articles arXiv:1309.0458 (ITCS 2014) \r\n and arXiv:1309.1151 (TCC 2014).\\n\r\nDTEND:20131203T221500Z\r\nDTSTAMP:20131119T230811\r\nDTSTART:20131203T211500Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131118T153644\r\nLOCATION:32-G449\r\nSEQUENCE:0\r\nSUMMARY:Capacity and Constructions of Non-Malleable Codes\r\nUID:2013-11-19T23:08:11-05:00_485897585@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131119T004029\r\nDESCRIPTION:It\'s easy to see the increasing costs of a sedentary culture\\, \r\n from pain and stress taking us out of work\\, to other lifestyle conditions \r\n costing health care services to treat. A challenge in HCI is to consider wh\r\n ere and how interactive technology may be developed to help address these i\r\n ssues\\, based on the sense that time with an app is cheaper and more readil\r\n y accessible than time with a human expert.  That said\\, much work around h\r\n ealth and wellbeing in HCI has focused on a single area: persuasive technol\r\n ogies to encourage people to maintain "healthy" practices\\, from moving mor\r\n e to eating less.  By looking at where and how people explore health practi\r\n ces\\, in the context of our daily lives\\, we see that such focus may repres\r\n ent only a small part of the design space for consideration\\, and perhaps n\r\n ot represent where the greatest challenge/benefit tradeoff for effect may b\r\n e. In this talk i\'ll go over a four part framework for a principled way to \r\n look at the design space for wellbeing\\, including (1) being in-bodied (as \r\n opposed to embodied) (2) decision cycles (3) routine practices and (4) tech\r\n nology as culture as technology. Looking forward to your thoughts and feedb\r\n ack.\\n\\nbio: m.c. schraefel\\, ph.d\\, f.bcs\\, c.eng\\, cscs\\, holds the post \r\n Professor of Computer Science and Human Performance in the Agents\\, Interac\r\n tion and Complexity Group of Electronics and Computer Science\\, University \r\n of Southampton\\, UK (http://www.ecs.soton.ac.uk/~mc). mc also holds a Resea\r\n rch Chair sponsored by the Royal Academy of Engineering and Microsoft Resea\r\n rch UK to investigate how to design interactive technology to better suppor\r\n t creativity\\, innovation and discovery. As part of that research\\, schraef\r\n el utilises her work with athletes and researchers as a professional streng\r\n th and conditioning\\, movement and nutrition coach for unique insights into\r\n  people\'s longitudinal experience of and challenges with wellbeing practice\r\n . \\nmc can be found on twitter / facebook @mcphoo\\nher wellbeing coaching l\r\n ikewise @begin2dig and begin2dig.com\r\nDTEND:20131122T190000Z\r\nDTSTAMP:20131119T230811\r\nDTSTART:20131122T180000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131119T101826\r\nLOCATION:32-G449 (Kiva)\r\nSEQUENCE:0\r\nSUMMARY:Charting the space of wellbeing design for HCI Research and Evaluat\r\n ion in Four movements\r\nUID:2013-11-19T23:08:11-05:00_213456362@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131119T101449\r\nDESCRIPTION:In a seminal 2001 article in the Scientific American\\, Tim Bern\r\n ers-Lee\\, Jim Hendler\\, and Ora Lassila laid out their vision of the Semant\r\n ic Web. In this vision\\, software agents use machine understandable "semant\r\n ic" data to do everything for us from scheduling appointments to booking ti\r\n ckets and even identifying appropriate healthcare providers. However\\, this\r\n  vision did not turn into a reality and the Semantic Web failed to take off\r\n . In 2006\\, Tim Berners-Lee and others proposed a set of simple design prin\r\n ciples\\, Linked Data\\, that used a subset of Semantic Web standards to enab\r\n le structured data to be easily found\\, exchanged\\, and manipulated. This m\r\n ore foundational element of the Semantic Web moved away from large complex \r\n ontologies to simpler semantics with a view of pushing machine understandab\r\n le data to the forefront. The last few years have seen an astronomic rise i\r\n n the amount of Linked Data online. However\\, Linked Data has yet to reach \r\n the pace at which the Web is growing. Why isn\xe2\x80\x99t there more Linked Data? Wha\r\n t are the factors preventing greater deployment and use of Linked Data? Is \r\n it all a matter of engineering or are there any research challenges? Is Lin\r\n ked Data a good idea\\, or simply a rebranding of the Semantic Web? What is \r\n the vision for Linked Data? Come and hear experts in the field debate these\r\n  and other questions related to the challenges of Linked Data.\\n\\nPanelists\r\n :\\nTim Berners-Lee: http://www.w3.org/People/Berners-Lee/\\nHelena F. Deus: \r\n http://lenadeus.info\\nJim Hendler http://www.cs.rpi.edu/~hendler/\\nDavid Ka\r\n rger: http://people.csail.mit.edu/karger/\\nMona Vernon: http://gracehopper.\r\n org/2013/speaker/mona-vernon/\\nDavid Wood: http://3roundstones.com/about-us\r\n /leadership-team/david-wood/\r\nDTEND:20131126T193000Z\r\nDTSTAMP:20131119T230811\r\nDTSTART:20131126T180000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131119T101449\r\nLOCATION:32-155\r\nSEQUENCE:0\r\nSUMMARY:Panel on Challenges of Linked Data\r\nUID:2013-11-19T23:08:11-05:00_841837956@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131119T132403\r\nDESCRIPTION:Recent technology scaling has led to the realization that commu\r\n nication\\, and not computation\\, dominates energy costs. This realization\\,\r\n  coupled with the constant increase of parallelism and the fact that power \r\n consumption is typically the primary design constraint\\, results in increas\r\n ed difficulty in providing sufficient communication bandwidth to keep proce\r\n ssors busy. Power is a critical challenge for HPC\\, datacenters and consume\r\n r electronics. In HPC\\, a 1000x improvement is performance is needed with o\r\n nly a 10x increase in power by 2018. Moreover\\, datacenters require $7B jus\r\n t for cooling in the USA\\, which is projected to increase by four times in \r\n the near future. Finally\\, consumer electronics require a 2x increase in pe\r\n rformance with no increase in power every two years to remain competitive.\\\r\n nIn this talk\\, I will present a my work that addresses efficient data move\r\n ment on and off chips\\, and DRAM access. I will focus on collective memory \r\n transfers\\, which maximize DRAM performance and minimize power in stencil c\r\n omputations by guaranteeing in-order access patterns. I will also focus on \r\n the channel reservation protocol\\, which eliminates congestion in system-wi\r\n de networks in order to increase throughput and reduce latency for benign t\r\n raffic\\, and therefore increase the utilization of costly network bandwidth\r\n .\\n\\nBio:\\n\\nGeorge Michelogiannakis is currently a postdoctoral research f\r\n ellow at the Lawrence Berkeley National Laboratory. He is part of the compu\r\n ter architecture laboratory which examines key computer architecture resear\r\n ch challenges both on and off chip. He completed his PhD at Stanford Univer\r\n sity in 2012 with Prof. William J. Dally. His past work focuses on on-chip \r\n network with numerous contributions to flow control\\, congestion\\, allocati\r\n on\\, and co-design with chip multiprocessors. His other work includes conge\r\n stion control for system-wide networks\\, precision loss avoidance for syste\r\n m-wide reduction operations\\, and maximizing DRAM efficiency by taking adva\r\n ntage of advanced language constructs. George Michelogiannakis was the reci\r\n pient of the Stanford Graduate Fellowship\\, and numerous other awards durin\r\n g his previous studies. \r\nDTEND:20131204T210000Z\r\nDTSTAMP:20131119T230811\r\nDTSTART:20131204T193000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131119T132403\r\nLOCATION:32-G882\r\nSEQUENCE:0\r\nSUMMARY:The constant battle for power-efficient computing \r\nUID:2013-11-19T23:08:11-05:00_468898772@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131119T152232\r\nDESCRIPTION:Abstract: In this talk I will describe nondeterministic reducti\r\n ons which yield new direct product theorems (DPTs) for Boolean circuits. In\r\n  our theorems one assumes that a function F is "mildly hard" against *nonde\r\n terministic* circuits of some size s(n)\\, and concludes that the t-fold dir\r\n ect product F^t is "extremely hard" against probabilistic circuits of only \r\n polynomially smaller size s\'(n). The main advantage of these results compar\r\n ed with previous DPTs is the strength of the size bound in our conclusion. \r\n As an application\\, we show that if NP is not in coNP/poly then\\, for every\r\n  PPT algorithm attempting to produce satisfying assignments to Boolean form\r\n ulas\\, there are infinitely many satisfiable instances on which the algorit\r\n hm\'s success probability is nearly-exponentially small. This furthers a pro\r\n ject of Paturi and Pudl\xc3\xa1k [STOC\'10].\r\nDTEND:20131210T221500Z\r\nDTSTAMP:20131119T230811\r\nDTSTART:20131210T211500Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131119T152232\r\nLOCATION:32-G449\r\nSEQUENCE:0\r\nSUMMARY:Nondeterministic Direct Product Reductions and the Success Probabil\r\n ity of SAT Solvers\r\nUID:2013-11-19T23:08:11-05:00_806586014@calendar\r\nEND:VEVENT\r\nBEGIN:VEVENT\r\nCREATED:20131119T152904\r\nDESCRIPTION:Abstract:\\nThe wide adoption of smartphones has made cellular n\r\n etworks an essential part\\nof our digital life. However\\, existing cellular\r\n  networks suffer from two key\\nproblems: the lack of access bandwidth and t\r\n he lack of direct control.\\n\\nIn this talk\\, I will present techniques to a\r\n ddress these two key problems\\nthrough the principle of design-in-the-large\r\n . Design-in-the-large leverages the\\nnumerous and their emergent behaviors \r\n to achieve scalability and flexibility.\\n\\nIn particular\\, to scale access \r\n bandwidth at radio access networks\\, I\\nwill present the design and prototy\r\n pe of Argos\\, a base station\\narchitecture that employs an unprecedented nu\r\n mber of antennas\\nsimultaneously to serve a smaller number of mobile device\r\n s in the same\\nband of frequencies. Both analysis and early experimental re\r\n sults\\nsuggest this design can lead to orders of magnitude increase in both\r\n \\nspectral and energy efficiency.\\n\\nTo enable direct control of both radio\r\n  access networks and cellular core\\nnetworks\\, I will present the design an\r\n d prototype of SoftRAN and SoftCell\\nrespectively. SoftRAN is a software de\r\n fined centralized control plane for radio\\naccess networks that abstracts a\r\n ll base base stations in a region as a vritual\\nbig-base stations. SoftCell\r\n  is a software-defined cellular core network\\narchitecture that achieves sc\r\n alability by moving functionality from packet\\ngateways to the many base st\r\n ations and by aggregating traffic along multiple\\ndimensions\xe2\x80\x94the service po\r\n licy\\, the base station\\, and the mobile device\xe2\x80\x94at\\ndifferent switches in t\r\n he network.\\n\\nThis is joint work with collaborators at Princeton\\, Rice\\, \r\n Stanford\\, Yale and\\nBell Labs.\\n\\nBio:\\nLi Erran Li received his Ph.D. in \r\n Computer Science from Cornell\\nUniversity. Since graduation\\, he has been w\r\n ith Bell Labs. He is also an\\nadjunct professor at the Department of Comput\r\n er Science at Columbia\\nUniversity\\, New York. He is an IEEE Fellow. His re\r\n search interests are in\\nnetworking and systems with a focus on cellular ne\r\n tworks and mobile\\ncomputing. He has published over 70 papers and holds 13 \r\n US Patents. \r\nDTEND:20131121T210000Z\r\nDTSTAMP:20131119T230811\r\nDTSTART:20131121T200000Z\r\nCLASS:PUBLIC\r\nLAST-MODIFIED:20131119T152904\r\nLOCATION:32-124\r\nSEQUENCE:0\r\nSUMMARY:Making Cellular Networks Scalable and Flexible \r\nUID:2013-11-19T23:08:11-05:00_935085508@calendar\r\nEND:VEVENT\r\nEND:VCALENDAR\r\n'
p199
ss.